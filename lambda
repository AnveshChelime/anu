import boto3 # type: ignore
import os
import time
import json

ec2 = boto3.client('ec2')
autoscaling = boto3.client('autoscaling')
ssm = boto3.client('ssm')

def lambda_handler(event, context):
    try:
        # Fetch AMI ID from SSM Parameter Store
        parameter_name = "/ami/linux/test"
        response = ssm.get_parameter(Name=parameter_name)
        ami_id = response['Parameter']['Value']
        print(f"Retrieved AMI ID: {ami_id}")
    except Exception as e:
        print(f"Failed to fetch AMI from Parameter Store: {e}")
        return

    # Fetch configurations from environment variables
    excluded_instances = os.environ.get("EXCLUDED_INSTANCES", "").split(",")
    excluded_asgs = os.environ.get("EXCLUDED_ASGS", "").split(",")
    asg_configurations = json.loads(os.environ.get("ASG_CONFIGURATIONS", "{}"))

    try:
        # Process Auto Scaling Groups (ASG)
        print("Processing ASGs...")
        asgs = autoscaling.describe_auto_scaling_groups()['AutoScalingGroups']
        for asg in asgs:
            asg_name = asg['AutoScalingGroupName']

            # Skip excluded ASGs
            if asg_name in excluded_asgs:
                print(f"Skipping ASG: {asg_name}")
                continue

            # Update ASG configurations if defined
            if asg_name in asg_configurations:
                config = asg_configurations[asg_name]
                print(f"Updating ASG {asg_name} with configurations: {config}")
                autoscaling.update_auto_scaling_group(
                    AutoScalingGroupName=asg_name,
                    MinSize=config['min'],
                    MaxSize=config['max'],
                    DesiredCapacity=config['desired']
                )

            # Update Launch Template with new AMI
            if 'LaunchTemplate' in asg:
                launch_template_id = asg['LaunchTemplate']['LaunchTemplateId']
                current_version = asg['LaunchTemplate']['Version']
                print(f"ASG {asg_name} is using Launch Template: {launch_template_id}, Version: {current_version}")

                # Create a new version of the launch template with the new AMI
                response = ec2.create_launch_template_version(
                    LaunchTemplateId=launch_template_id,
                    SourceVersion=current_version,
                    LaunchTemplateData={'ImageId': ami_id}
                )
                new_version = response['LaunchTemplateVersion']['VersionNumber']
                print(f"Created new Launch Template Version: {new_version} for ASG: {asg_name}")

                # Update the ASG to use the new launch template version
                autoscaling.update_auto_scaling_group(
                    AutoScalingGroupName=asg_name,
                    LaunchTemplate={
                        'LaunchTemplateId': launch_template_id,
                        'Version': str(new_version)
                    }
                )
                print(f"Updated ASG {asg_name} to use Launch Template version {new_version}")
            else:
                print(f"ASG {asg_name} does not have a Launch Template. Skipping Launch Template update.")

            # Capture volumes for instances in ASG
            volumes_to_reattach = {}
            for instance in asg['Instances']:
                instance_id = instance['InstanceId']
                print(f"Capturing volumes for instance {instance_id}...")
                volumes = ec2.describe_volumes(Filters=[{'Name': 'attachment.instance-id', 'Values': [instance_id]}])
                volumes_to_reattach[instance_id] = [
                    {'VolumeId': volume['VolumeId'], 'Device': attachment['Device']}
                    for volume in volumes['Volumes']
                    for attachment in volume['Attachments']
                    if attachment['Device'] != '/dev/xvda'  # Exclude root volume
                ]
                print(f"Captured volumes for instance {instance_id}: {volumes_to_reattach[instance_id]}")

            # Start instance refresh for ASG
            print(f"Starting instance refresh for ASG: {asg_name}")
            autoscaling.start_instance_refresh(AutoScalingGroupName=asg_name)
            print(f"Waiting for new instances to be launched in ASG: {asg_name}")
            time.sleep(500)  # Adjust as needed

            # Fetch refreshed instances
            refreshed_instances = ec2.describe_instances(Filters=[
                {'Name': 'tag:aws:autoscaling:groupName', 'Values': [asg_name]},
                {'Name': 'instance-state-name', 'Values': ['running']}
            ])
            refreshed_instance_ids = [
                instance['InstanceId']
                for reservation in refreshed_instances['Reservations']
                for instance in reservation['Instances']
            ]
            print(f"Refreshed instance IDs for ASG {asg_name}: {refreshed_instance_ids}")

            # Ensure mapping of old instances to new instances
            if len(volumes_to_reattach) != len(refreshed_instance_ids):
                print(f"Mismatch in number of old instances ({len(volumes_to_reattach)}) and refreshed instances ({len(refreshed_instance_ids)})")
                return

            old_to_new_mapping = dict(zip(volumes_to_reattach.keys(), refreshed_instance_ids))
            print(f"Mapping of old to new instances: {old_to_new_mapping}")

            # Reattach volumes to the correct instances
            for old_instance_id, new_instance_id in old_to_new_mapping.items():
                print(f"Reattaching volumes from old instance {old_instance_id} to new instance {new_instance_id}...")
                for volume in volumes_to_reattach[old_instance_id]:
                    volume_id = volume['VolumeId']
                    device_name = volume['Device']

                    # Check volume state before reattaching
                    volume_details = ec2.describe_volumes(VolumeIds=[volume_id])
                    attachment_state = (
                        volume_details["Volumes"][0]["Attachments"][0]["State"]
                        if volume_details["Volumes"][0]["Attachments"]
                        else "detached"
                    )

                    if attachment_state == "attached":
                        print(f"Skipping reattachment of volume {volume_id} as it is already attached.")
                        continue

                    try:
                        print(f"Reattaching volume {volume_id} to instance {new_instance_id} on device {device_name}...")
                        ec2.attach_volume(
                            VolumeId=volume_id,
                            InstanceId=new_instance_id,
                            Device=device_name
                        )
                    except Exception as e:
                        print(f"Failed to reattach volume {volume_id} to instance {new_instance_id}: {e}")
                    print("ASG updates, refresh, and volume reattachments completed successfully.")
    except Exception as e:
        print(f"Error updating ASGs: {e}")


    try:
        # Perform updates on standalone instances
        print("Updating standalone EC2 instances...")
        standalone_instances = []
        instances = ec2.describe_instances()
        for reservation in instances.get('Reservations', []):
            for instance in reservation.get('Instances', []):
                instance_id = instance.get('InstanceId')
                state = instance.get('State', {}).get('Name')

                # Skip excluded or non-running instances
                if instance_id in excluded_instances or state != "running":
                    print(f"Excluding instance {instance_id} (state: {state})")
                    continue

                # Check if the instance is part of an ASG
                tags = {tag['Key']: tag['Value'] for tag in instance.get('Tags', [])}
                if 'aws:autoscaling:groupName' in tags:
                    print(f"Skipping ASG-managed instance: {instance_id} (ASG: {tags['aws:autoscaling:groupName']})")
                    continue

                # Add standalone instance to the list
                standalone_instances.append(instance)

        print(f"Standalone instances to update: {standalone_instances}")

        # Perform updates on standalone instances
        for instance in standalone_instances:
            instance_id = instance['InstanceId']
            subnet_id = instance['SubnetId']
            instance_type = instance['InstanceType']
            security_groups = [sg['GroupId'] for sg in instance.get('SecurityGroups', [])]

            # Capture and terminate standalone instance volumes
            volumes = ec2.describe_volumes(Filters=[{'Name': 'attachment.instance-id', 'Values': [instance_id]}])
            captured_volumes = []
            for volume in volumes['Volumes']:
                volume_id = volume['VolumeId']
                device_name = volume['Attachments'][0]['Device']
                if device_name != '/dev/xvda':  # Exclude root volume
                    captured_volumes.append({'VolumeId': volume_id, 'Device': device_name})
                    print(f"Captured volume {volume_id} (Device: {device_name}) for instance {instance_id}")

            # Terminate instance
            print(f"Terminating standalone instance: {instance_id}")
            ec2.terminate_instances(InstanceIds=[instance_id])
            time.sleep(100)  # Allow time for termination

            try:
                # Recreate instance
                print(f"Recreating standalone instance: {instance_id} with AMI: {ami_id}")
                print(f"recreating with SubnetId: {subnet_id}, SecurityGroups: {security_groups}")

                new_instance = ec2.run_instances(
                    ImageId=ami_id,
                    MinCount=1,
                    MaxCount=1,
                    InstanceType=instance_type,
                    SubnetId=subnet_id,
                    SecurityGroupIds=security_groups
                    )['Instances'][0]

                new_instance_id = new_instance['InstanceId']
                print(f"New instance created: {new_instance_id}")

                # Wait for the instance to stabilize
                print(f"Waiting for instance {new_instance_id} to reach running state...")
                time.sleep(150)  # Allow instance to stabilize

                # Validate instance state
                response = ec2.describe_instances(InstanceIds=[new_instance_id])
                state = response['Reservations'][0]['Instances'][0]['State']['Name']
                if state != "running":
                    state_reason = response['Reservations'][0]['Instances'][0].get('StateReason', {})
                    print(f"Instance {new_instance_id} is in state: {state}. Termination reason: {state_reason}")
                    return
                print(f"Instance {new_instance_id} is now running.")

                # Reattach volumes
                for volume in captured_volumes:
                    volume_id = volume['VolumeId']
                    device_name = volume['Device']
                    try:
                        print(f"Reattaching volume {volume_id} to instance {new_instance_id} on device {device_name}...")
                        ec2.attach_volume(
                            VolumeId=volume_id,
                            InstanceId=new_instance_id,
                            Device=device_name
                        )
                    except Exception as e:
                        print(f"Failed to reattach volume {volume_id} to instance {new_instance_id}: {e}")
            except Exception as e:
                print(f"Failed to recreate standalone instance {instance_id}: {e}")

        print("Standalone instance refresh completed successfully.")
    except Exception as e:
        print(f"Error updating standalone EC2 instances: {e}")


import boto3
import requests
import os
import json

# AWS Clients
ec2_client = boto3.client("ec2")
ssm_client = boto3.client("ssm")
secrets_client = boto3.client("secretsmanager")  # ✅ Add Secrets Manager client

# Retrieve Terraform API Token from AWS Secrets Manager
def get_tfc_api_token():
    secret_name = "TFC_API_TOKEN"  # ✅ Replace with your secret name
    try:
        response = secrets_client.get_secret_value(SecretId=secret_name)
        return response["SecretString"] if "SecretString" in response else None
    except Exception as e:
        print(f"Error retrieving secret: {e}")
        return None

# Get latest AMI from SSM Parameter Store
def get_latest_ami():
    response = ssm_client.get_parameter(Name=os.environ["AMI_PARAMETER_NAME"])
    return response["Parameter"]["Value"]

# Get EC2 instances running OLD AMI and extract workspace_id
def get_workspace_ids(old_ami):
    workspace_ids = set()
    instances = ec2_client.describe_instances(
        Filters=[{"Name": "image-id", "Values": [old_ami]}]
    )

    for reservation in instances["Reservations"]:
        for instance in reservation["Instances"]:
            for tag in instance.get("Tags", []):
                if tag["Key"] == "workspace_id":
                    workspace_ids.add(tag["Value"])

    return list(workspace_ids)

# Get list of workspaces from Terraform Cloud
def get_tf_workspaces():
    response = requests.get(
        f"https://app.terraform.io/api/v2/organizations/{ORG_NAME}/workspaces",
        headers=HEADERS,
    )
    return response.json()["data"]

# Find matching Terraform workspaces
def find_matching_workspaces(workspace_ids):
    workspaces = get_tf_workspaces()
    return [
        ws["id"] for ws in workspaces if ws["attributes"]["name"] in workspace_ids
    ]

# Trigger Terraform Cloud Run
def trigger_tf_run(workspace_id):
    payload = {
        "data": {
            "attributes": {
                "message": "AMI update - Triggering ASG refresh",
                "is-destroy": False
            },
            "relationships": {
                "workspace": {
                    "data": {
                        "type": "workspaces",
                        "id": workspace_id
                    }
                }
            }
        }
    }
    
    response = requests.post(
        "https://app.terraform.io/api/v2/runs",
        headers=HEADERS,
        json=payload,
    )

    print(f"Triggered Terraform Run for {workspace_id}: {response.status_code}")

# Lambda Handler Function
def lambda_handler(event, context):
    # Get Old AMI from event (EventBridge sends parameter name, fetch previous value)
    old_ami = event["detail"]["oldValue"]
    latest_ami = get_latest_ami()

    # Find workspace IDs based on EC2 instances
    workspace_ids = get_workspace_ids(old_ami)

    if not workspace_ids:
        print("No matching EC2 instances found for the old AMI.")
        return

    # Find matching Terraform Cloud Workspaces
    matching_workspaces = find_matching_workspaces(workspace_ids)

    if not matching_workspaces:
        print("No matching Terraform Cloud Workspaces found.")
        return

    # Trigger Terraform runs for each matching workspace
    for ws_id in matching_workspaces:
        trigger_tf_run(ws_id)

    return {"statusCode": 200, "body": "Terraform runs triggered successfully."}

